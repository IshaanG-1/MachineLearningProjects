{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9a1a1f",
   "metadata": {},
   "source": [
    "# Problem 5:\n",
    "\n",
    "### a.\n",
    "\n",
    "The model matrix A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59bf9502",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16×2 Matrix{Int64}:\n",
       " 1   5000\n",
       " 1   5200\n",
       " 1   6000\n",
       " 1   6538\n",
       " 1   7109\n",
       " 1   7556\n",
       " 1   8005\n",
       " 1   8207\n",
       " 1   8210\n",
       " 1   8600\n",
       " 1   9026\n",
       " 1   9197\n",
       " 1   9926\n",
       " 1  10813\n",
       " 1  13800\n",
       " 1  14311"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1; 1; 1; 1; 1; 1; 1; 1; 1; 1 ;1; 1; 1; 1; 1; 1;; 5000; 5200; 6000; 6538; 7109; 7556; 8005; 8207; 8210; 8600; 9026; 9197; 9926; 10813; 13800; 14311]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43315f8b",
   "metadata": {},
   "source": [
    "The response vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e185454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16-element Vector{Float64}:\n",
       "  2596.8\n",
       "  3328.0\n",
       "  3181.1\n",
       "  3198.4\n",
       "  4779.9\n",
       "  5905.6\n",
       "  5769.2\n",
       "  8089.5\n",
       "  4813.1\n",
       "  5618.7\n",
       "  7736.0\n",
       "  6788.3\n",
       "  7840.8\n",
       "  8882.5\n",
       " 10489.5\n",
       " 12506.6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [2596.8;3328 ;3181.1 ;3198.4 ;4779.9; 5905.6; 5769.2; 8089.5; 4813.1; 5618.7; 7736; 6788.3; 7840.8; 8882.5; 10489.5; 12506.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e6292",
   "metadata": {},
   "source": [
    "### b.\n",
    "\n",
    "The function for the gradient evaluated at point x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abd680a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "function ∇f(x::Vector)\n",
    "    return A'*A*x - A'*b\n",
    "end\n",
    "f(x) = 0.5 * norm(A*x - b)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377caa1",
   "metadata": {},
   "source": [
    "### c.\n",
    "\n",
    "The function for the Hessian evaluated at point x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b4e2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hessian (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Hessian()\n",
    "    return A' * A\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebb1c1",
   "metadata": {},
   "source": [
    "### d.\n",
    "\n",
    "The steepest descent function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d333b387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steepest_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra \n",
    "\n",
    "function steepest_descent(x; k = 1000)\n",
    "    i = 1\n",
    "    while norm(∇f(x)) > 1e-1 && i < 10000\n",
    "        p = (-I) * ∇f(x)\n",
    "        x = x + 0.000000001 * p #step_size was determined through backtracking and approximated to this value for ease\n",
    "        if i % k == 0 \n",
    "            println(\"iteration \", i, \". x = \", x)\n",
    "        end\n",
    "        i+=1\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ade5d1",
   "metadata": {},
   "source": [
    "### e.\n",
    "\n",
    "Newton's Method Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26eb58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton_method (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function newton_method(x; k = 1)\n",
    "    i = 1\n",
    "    while norm(∇f(x)) > 1e-1 && i < 10000\n",
    "        B = inv(Hessian())\n",
    "        p = - B * ∇f(x)\n",
    "        x = x + p\n",
    "        if i % k == 0 \n",
    "            println(\"iteration \", i, \". x = \", x)\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e84baf",
   "metadata": {},
   "source": [
    "### f.\n",
    "\n",
    "Using the initial guess of (-2200, 0.5)^T, evaluation of the two methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed095350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1000. x = [-2200.0000489685203, 0.9951113881973228]\n",
      "iteration 2000. x = [-2200.0001507932734, 0.9951113990677681]\n",
      "iteration 3000. x = [-2200.0002526180265, 0.9951114099382137]\n",
      "iteration 4000. x = [-2200.000354442582, 0.995111420808638]\n",
      "iteration 5000. x = [-2200.0004562668805, 0.9951114316790352]\n",
      "iteration 6000. x = [-2200.000558091179, 0.9951114425494321]\n",
      "iteration 7000. x = [-2200.0006599154526, 0.9951114534198262]\n",
      "iteration 8000. x = [-2200.000761739296, 0.9951114642901747]\n",
      "iteration 9000. x = [-2200.00086356314, 0.9951114751605232]\n",
      "Steepest Descent Method: [-2200.0009652851595, 0.9951114860200011]\n",
      "iteration 1. x = [-2277.069654638195, 1.0033390629260879]\n",
      "Newton's Method: [-2277.069654638195, 1.0033390629260879]\n"
     ]
    }
   ],
   "source": [
    "x = [-2200;0.5]\n",
    "\n",
    "println(\"Steepest Descent Method: \", steepest_descent(x))\n",
    "println(\"Newton's Method: \", newton_method(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f3056",
   "metadata": {},
   "source": [
    "As we can see above, the steepest descent model takes quite a few more iterations to run, and this is even when the method was forced to stop at 10000 iterations. If the steepest_descent model is given enough iterations, or given a point far closer to the ideal, it will eventually converge to the ideal solution, but incredibly slow (this was tested just to make sure that the model wasn't broken)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64982088",
   "metadata": {},
   "source": [
    "### g.\n",
    "\n",
    "Regression model fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea91ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}\n",
       "\n",
       "Y ~ 1 + X\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.   Std. Error      t  Pr(>|t|)     Lower 95%   Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  -2277.07     765.499      -2.97    0.0100  -3918.9       -635.238\n",
       "X                1.00334    0.0853205  11.76    <1e-07      0.820345     1.18633\n",
       "────────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, GLM\n",
    "\n",
    "data = DataFrame(X = [5000, 5200, 6000, 6538, 7109, 7556, 8005, 8207, 8210, 8600, 9026, 9197, 9926, 10813, 13800, 14311], \n",
    "    Y = [2596.8, 3328, 3181.1, 3198.4, 4779.9, 5905.6, 5769.2, 8089.5, 4813.1, 5618.7, 7736, 6788.3, 7840.8, 8882.5, 10489.5, 12506.6])\n",
    "\n",
    "lm(@formula(Y ~ X), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fa740b",
   "metadata": {},
   "source": [
    "As we can see from the intercept and X coeffiecients, we can see that the estimates for Newton's method match exactly with the regression lm() model but the steepest descent is slightly off, especially for the intercept term. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74761c",
   "metadata": {},
   "source": [
    "Since Newton's method is a 2nd order differential method (using the Hessian) whereas steepest descent is a 1st order (using the gradient), the method is able to find a more accurate model of convergence and even converge towards minimizing residuals faster in less steps (1 iteration for Newton's method and more than 10000 for steepest descent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
